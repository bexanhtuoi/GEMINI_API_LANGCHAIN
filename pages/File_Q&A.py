import streamlit as st
from langchain.text_splitter import RecursiveCharacterTextSplitter
from PyPDF2 import PdfReader
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain.vectorstores import DocArrayInMemorySearch
from langchain_google_genai import GoogleGenerativeAI
from langchain.chains import RetrievalQA

st.header('Introduce ğŸ“ƒ')
st.markdown("File Q&A lÃ  má»™t há»‡ thá»‘ng tá»± Ä‘á»™ng hÃ³a giÃºp báº¡n nhanh chÃ³ng truy xuáº¥t thÃ´ng tin tá»« cÃ¡c tÃ i liá»‡u cháº³ng háº¡n nhÆ° file PDF. Há»‡ thá»‘ng Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ há»— trá»£ tráº£ lá»i cÃ¢u há»i tá»« ná»™i dung tÃ i liá»‡u má»™t cÃ¡ch chÃ­nh xÃ¡c vÃ  hiá»‡u quáº£. ğŸ¦¾")
with st.sidebar:
    API_input = st.text_input("Gemini API Key" , type="password")
    st.title('Your Document')
    file = st.file_uploader("Upload a file PDF file and start asking question", type ='pdf')

if file is not None:
    pdf_reader = PdfReader(file)
    text= ""
    for page in pdf_reader.pages:
        text+= page.extract_text()

    # CÆ¡ cháº¿ chunk nha máº¥y nÃ­
    text_splitter  = RecursiveCharacterTextSplitter(
        separators= '\n', # Ra yÃªu cáº§u phÃ¢n tÃ¡ch cÃ¡c Ä‘oáº¡n báº±ng kÃ­ tá»± xuá»‘ng dÃ²ng
        chunk_size = 1000, # Ä‘á»™ dÃ i cá»§a má»—i Ä‘oáº¡n lÃ  1000 kÃ­ tá»±
        chunk_overlap = 150, # mang 150 kÃ­ tá»± tá»« Ä‘oáº¡n trÆ°á»›c vÃ o Ä‘oáº¡n sau Ä‘á»ƒ táº¡o má»‘i liÃªn káº¿t giá»¯a cÃ¡c Ä‘oáº¡n
        length_function = len
    )

    chunk = text_splitter.split_text(text)
    chunk = [text.replace('\n', '') for text in chunk]
    user_input = st.text_input("Enter what you want to ask the file here ğŸ‘‡" , key="user_input")

    if user_input:
        if not API_input:
            st.warning("Please enter your [API](https://ai.google.dev/) into sidebar.")
        else:
            try:
                embeddings = GoogleGenerativeAIEmbeddings(google_api_key=API_input, model="models/embedding-001")

                vectorstore = DocArrayInMemorySearch.from_texts(chunk,
                    embedding=embeddings 
                )

                llm = GoogleGenerativeAI(
                        model="gemini-pro",
                        temperature=0.7,
                        google_api_key=API_input
                    )

                qa_chain = RetrievalQA.from_chain_type(
                    llm=llm,
                    chain_type="stuff",
                    retriever=vectorstore.as_retriever()
                )

                answer = qa_chain.invoke(user_input)
                st.write(answer['result'])
            except Exception:
                st.error('Please enter the correct [API](https://ai.google.dev/) Key')

else:
    st.info('Please upload a file')